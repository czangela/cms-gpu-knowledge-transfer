
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.2.3, mkdocs-material-8.0.0b1">
    
    
      
        <title>Week 01 - 2021.12.06-10. - CMS Tracker DPG - knowledge transfer workshop</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.450eaa28.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.9204c3b2.min.css">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>function __md_scope(e,t,_){return new URL(_||(t===localStorage?"../../..":"../../.."),location).pathname+"."+e}function __md_get(e,t=localStorage,_){return JSON.parse(t.getItem(__md_scope(e,t,_)))}function __md_set(e,t,_=localStorage,o){try{_.setItem(__md_scope(e,_,o),JSON.stringify(t))}catch(e){}}</script>
    
      

  


  

  


  <script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-ZZ8D6PMHP5"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){this.value&&gtag("event","search",{search_term:this.value})}),"undefined"!=typeof location$&&location$.subscribe(function(e){gtag("config","G-ZZ8D6PMHP5",{page_path:e.pathname})})})</script>
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-ZZ8D6PMHP5"></script>


    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="none" data-md-color-accent="none">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#week-01-20211206-10" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="CMS Tracker DPG - knowledge transfer workshop" class="md-header__button md-logo" aria-label="CMS Tracker DPG - knowledge transfer workshop" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            CMS Tracker DPG - knowledge transfer workshop
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Week 01 - 2021.12.06-10.
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="CMS Tracker DPG - knowledge transfer workshop" class="md-nav__button md-logo" aria-label="CMS Tracker DPG - knowledge transfer workshop" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    CMS Tracker DPG - knowledge transfer workshop
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_2">
          Getting-started
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Getting-started" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          Getting-started
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../getting-started/" class="md-nav__link">
        Connecting to GPU machines
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../getting-started/software/" class="md-nav__link">
        General CMSSW developer guide
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../getting-started/validation/" class="md-nav__link">
        Workflows
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3">
          Documentation
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Documentation" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Documentation
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../documentation/gpuClustering/" class="md-nav__link">
        gpuClustering.h - findClus
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../documentation/gpuClustering02/" class="md-nav__link">
        gpuClustering.h - countModules
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" type="checkbox" id="__nav_4" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4">
          Archive
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Archive" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          Archive
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../" class="md-nav__link">
        Archived resources
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    Introduction
  </a>
  
    <nav class="md-nav" aria-label="Introduction">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-cuda-a-general-purpose-parallel-computing-platform-and-programming-model" class="md-nav__link">
    1. CUDA®: A General-Purpose Parallel Computing Platform and Programming Model
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-a-scalable-programming-model" class="md-nav__link">
    2. A Scalable Programming Model
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#programming-model" class="md-nav__link">
    Programming model
  </a>
  
    <nav class="md-nav" aria-label="Programming model">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#3-kernels" class="md-nav__link">
    3. Kernels
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4-thread-hierarchy" class="md-nav__link">
    4. Thread hierarchy
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#5-language-extensions" class="md-nav__link">
    5. Language extensions
  </a>
  
    <nav class="md-nav" aria-label="5. Language extensions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#__global__" class="md-nav__link">
    __global__
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#__device__" class="md-nav__link">
    __device__
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#__host__" class="md-nav__link">
    __host__
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#6-execution-configuration" class="md-nav__link">
    6. Execution Configuration
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#abstractions-granularity" class="md-nav__link">
    Abstractions: Granularity
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                
                
<h1 id="week-01-20211206-10">Week 01 - 2021.12.06-10.</h1>
<details class="info" open="open"><summary>Overview</summary><ul>
<li>What is the CUDA programming model?</li>
<li>Hierarchy of thread groups</li>
<li>Kernels and other language extensions</li>
</ul>
</details>
<details class="tip" open="open"><summary>Resources</summary><p>This material heavily borrows from the following sources:</p>
<ul>
<li>
<p><a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html">CUDA C++ Programming Guide</a></p>
</li>
<li>
<p><a href="https://nyu-cds.github.io/python-gpu/02-cuda/">Introduction to GPUs by New York University</a></p>
</li>
<li>
<p><a href="https://indico.cern.ch/event/863657/">Introduction to parallel programming and CUDA by Felice Pantaleo</a></p>
</li>
</ul>
</details>
<h2 id="introduction">Introduction</h2>
<h3 id="1-cuda-a-general-purpose-parallel-computing-platform-and-programming-model">1. CUDA®: A General-Purpose Parallel Computing Platform and Programming Model</h3>
<p>In November 2006, NVIDIA®  introduced CUDA® , which originally stood for “Compute Unified Device Architecture”, a general purpose parallel computing platform and programming model that leverages the parallel compute engine in NVIDIA GPUs to solve many complex computational problems in a more efficient way than on a CPU.</p>
<p>CUDA comes with a software environment that allows developers to use C++ as a high-level programming language. Other languages, application programming interfaces, or directives-based approaches are supported, such as FORTRAN, DirectCompute, OpenACC.</p>
<p><img alt="GPU Computing Applications" src="https://docs.nvidia.com/cuda/cuda-c-programming-guide/graphics/gpu-computing-applications.png" /></p>
<h3 id="2-a-scalable-programming-model">2. A Scalable Programming Model</h3>
<details class="quote" open="open"><summary>At the core of the  CUDA parallel programming model there are three key abstractions:</summary><ul>
<li>a hierarchy of thread groups</li>
<li>shared memories</li>
<li>barrier synchronization</li>
</ul>
</details>
<p>They are exposed to the programmer as a <strong>minimal set of language extensions</strong>.</p>
<p>These abstractions provide <strong>fine-grained data parallelism and thread parallelism</strong>, nested within <strong>coarse-grained data parallelism and task parallelism</strong>.</p>
<div class="admonition tip">
<p class="admonition-title">Further reading and material</p>
<p>Optional reading and exercise on this topic at <a href="./week01/#abstractions-granularity">abstractions: granularity</a>.</p>
</div>
<h2 id="programming-model">Programming model</h2>
<h3 id="3-kernels">3. Kernels</h3>
<p>CUDA C++ extends C++ by allowing the programmer to define C++ functions, called <em>kernels</em>, that, when called, are executed <code>N</code> times in parallel by <code>N</code> different CUDA threads, as opposed to only once like regular C++ functions.</p>
<p>A kernel is defined using the <code>__global__</code> declaration specifier and the number of CUDA threads that execute that kernel for a given kernel call is specified using a new <code>&lt;&lt;&lt;...&gt;&gt;&gt;</code> execution configuration syntax.</p>
<p>Each thread that executes the kernel is given a <em>unique thread ID</em> that is accessible within the kernel through built-in variables.</p>
<details class="example" open="open"><summary>Kernel and execution configuration example</summary><div class="highlight"><pre><span></span><code><span class="c1">// Kernel definition</span>
<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">VecAdd</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">B</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">C</span><span class="p">)</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="n">C</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">B</span><span class="p">[</span><span class="n">i</span><span class="p">];</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>

<span class="kt">int</span><span class="w"> </span><span class="n">main</span><span class="p">()</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="p">...</span><span class="w"></span>
<span class="w">    </span><span class="c1">// Kernel invocation with N threads</span>
<span class="w">    </span><span class="n">VecAdd</span><span class="o">&lt;&lt;&lt;</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="n">B</span><span class="p">,</span><span class="w"> </span><span class="n">C</span><span class="p">);</span><span class="w"></span>
<span class="w">    </span><span class="p">...</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</code></pre></div>
</details>
<div class="admonition question">
<p class="admonition-title">01. Question: raw to digi conversion kernel</p>
<ul>
<li>Find the kernel that converts raw data to digis.</li>
<li>Where is it launched?</li>
<li>What is the execution configuration?</li>
<li>How do we access individual threads in the kernel?</li>
</ul>
<p><a href="../week01_exercises/#exercise_01_01">Go to exercise 01_01</a></p>
</div>
<h3 id="4-thread-hierarchy">4. Thread hierarchy</h3>
<p>A kernel is executed in parallel by an array of threads:</p>
<ul>
<li>All threads run the same code.</li>
<li>Each thread has an ID that it uses to compute memory addresses and make control decisions.</li>
</ul>
<p><img alt="thread_img_01" src="https://nyu-cds.github.io/python-gpu/fig/02-threadblocks.png" width="300" /></p>
<p>Threads are arranged as a grid of thread blocks:</p>
<ul>
<li>Different kernels can have different grid/block configuration</li>
<li>Threads from the same block have access to a shared memory and their execution can be synchronized</li>
</ul>
<p><img alt="thread_img_02" src="https://nyu-cds.github.io/python-gpu/fig/02-threadgrid.png" /></p>
<p>Thread blocks are required to execute independently: It must be possible to execute them in any order, in parallel or in series.</p>
<p>This independence requirement allows thread blocks to be scheduled in any order across any number of cores, enabling programmers to write code that scales with the number of cores.</p>
<p>Threads within a block can cooperate by sharing data through some shared memory and by synchronizing their execution to coordinate memory accesses.</p>
<p>The grid of blocks and the thread blocks can be 1, 2, or 3-dimensional.</p>
<p><img alt="thread_img_03" src="https://nyu-cds.github.io/python-gpu/fig/02-threadmapping.png" /></p>
<p>The CUDA architecture is built around a scalable array of multithreaded <strong>Streaming Multiprocessors</strong> (SMs) as shown below.</p>
<p>Each SM has a set of execution units, a set of registers and a chunk of shared memory.</p>
<p><img alt="sm_img_01" src="https://nyu-cds.github.io/python-gpu/fig/02-sm.png" /></p>
<h3 id="5-language-extensions">5. Language extensions</h3>
<p><a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#c-language-extensions">From CUDA Toolkit Documentation: Language Extensions</a>:</p>
<h4 id="__global__"><code>__global__</code></h4>
<p>The <strong>global</strong> execution space specifier declares a function as being a kernel. Such a function is:</p>
<ul>
<li>Executed on the device,</li>
<li>Callable from the host,</li>
<li>Callable from the device for devices of compute capability 3.2 or higher (see CUDA Dynamic Parallelism for more details).
A <strong>global</strong> function must have void return type, and cannot be a member of a class.</li>
</ul>
<p>Any call to a <strong>global</strong> function must specify its execution configuration as described in <a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#execution-configuration">Execution</a>.</p>
<p>A call to a <strong>global</strong> function is asynchronous, meaning it returns before the device has completed its execution.</p>
<h4 id="__device__"><code>__device__</code></h4>
<p>The <strong>device</strong> execution space specifier declares a function that is:</p>
<ul>
<li>Executed on the device,</li>
<li>Callable from the device only.</li>
</ul>
<p>The <strong>global</strong> and <strong>device</strong> execution space specifiers cannot be used together.</p>
<h4 id="__host__"><code>__host__</code></h4>
<p>The <strong>host</strong> execution space specifier declares a function that is:</p>
<ul>
<li>Executed on the host,</li>
<li>Callable from the host only.</li>
</ul>
<p>It is equivalent to declare a function with only the <strong>host</strong> execution space specifier or to declare it without any of the <strong>host</strong>, <strong>device</strong>, or <strong>global</strong> execution space specifier; in either case the function is compiled for the host only.</p>
<p>The <strong>global</strong> and <strong>host</strong> execution space specifiers cannot be used together.</p>
<p>The <strong>device</strong> and <strong>host</strong> execution space specifiers can be used together however, in which case the function is compiled for both the host and the device.</p>
<div class="admonition question">
<p class="admonition-title">02. Question: host and device functions</p>
<ul>
<li>
<p>Give an example of <code>global</code>, <code>device</code> and <code>host-device</code> functions in <code>CMSSW</code>.</p>
</li>
<li>
<p>Can you find an example where <code>host</code> and <code>device</code> code diverge? How is this achieved?</p>
</li>
</ul>
<p><a href="../week01_exercises/#exercise_01_02">Go to exercise 01_02</a></p>
</div>
<div class="admonition question">
<p class="admonition-title">03. Exercise: Write a kernel in which</p>
<ul>
<li>
<p>if we're running on the <code>device</code> each thread prints which <code>block</code> and <code>thread</code> it is associated with, for example <code>block 1 thread 3</code></p>
</li>
<li>
<p>if we're running on the <code>host</code> each thread just prints <code>host</code>.</p>
</li>
</ul>
<p><a href="../week01_exercises/#exercise_01_03">Go to exercise 01_03</a></p>
</div>
<h3 id="6-execution-configuration">6. Execution Configuration</h3>
<p><a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#execution-configuration">From CUDA Toolkit Documentation: Execution Configuration</a></p>
<p>Any call to a <strong>global</strong> function must specify the execution configuration for that call. The execution configuration defines the dimension of the grid and blocks that will be used to execute the function on the device, as well as the associated stream (see CUDA Runtime for a description of streams).</p>
<p>The execution configuration is specified by inserting an expression of the form <code>&lt;&lt;&lt; Dg, Db, Ns, S &gt;&gt;&gt;</code> between the function name and the parenthesized argument list, where:</p>
<ul>
<li>
<p><code>Dg</code> is of type dim3 (see dim3) and specifies the dimension and size of the grid, such that <code>Dg.x * Dg.y * Dg.z</code> equals the number of blocks being launched;</p>
</li>
<li>
<p><code>Db</code> is of type dim3 (see dim3) and specifies the dimension and size of each block, such that <code>Db.x * Db.y * Db.z</code> equals the number of threads per block;</p>
</li>
<li>
<p><code>Ns</code> is of type <code>size_t</code> and specifies the number of bytes in shared memory that is dynamically allocated per block for this call in addition to the statically allocated memory; this dynamically allocated memory is used by any of the variables declared as an external array as mentioned in <strong>shared</strong>; Ns is an optional argument which defaults to 0;</p>
</li>
<li>
<p><code>S</code> is of type <code>cudaStream_t</code> and specifies the associated stream; S is an optional argument which defaults to 0.</p>
</li>
</ul>
<h2 id="abstractions-granularity">Abstractions: Granularity</h2>
<details class="abstract" open="open"><summary>Granularity</summary><p>If <img alt="T_comp" src="https://latex.codecogs.com/svg.image?T_{comp}" /> is the computation time and <img alt="T_comm" src="https://latex.codecogs.com/svg.image?T_{comm}" /> denotes the communication time, then the Granularity G of a task can be calculated as</p>
<p><img alt="T_comp" src="https://latex.codecogs.com/svg.image?G=\frac{T_{comp}}{T_{comm}}" /></p>
<p>Granularity is usually measured in terms of the number of instructions executed in a particular task.</p>
</details>
<details class="abstract" open="open"><summary>Fine-grained parallelism</summary><p>Fine-grained parallelism means individual tasks are relatively small in terms of code size and execution time. The data is transferred among processors frequently in amounts of one or a few memory words.</p>
</details>
<details class="abstract" open="open"><summary>Coarse-grained parallelism</summary><p>Coarse-grained is the opposite in the sense that data is communicated infrequently, after larger amounts of computation.</p>
</details>
<p><img alt="Fine-course grained parallelism" src="https://raw.githubusercontent.com/czangela/cms-gpu-knowledge-transfer/gh-pages/img/w01_img02.png" /></p>
<p>The CUDA abstractions provide fine-grained data parallelism and thread parallelism, nested within coarse-grained data parallelism and task parallelism. They guide the programmer to partition the problem into <strong>coarse sub-problems</strong> that can be solved independently in parallel by blocks of threads, and each sub-problem into <strong>finer pieces that can be solved cooperatively in parallel by all threads within the block</strong>.</p>
<p>This decomposition preserves language expressivity by allowing threads to cooperate when solving each sub-problem, and at the same time enables automatic scalability.</p>
<p>Indeed, each block of threads can be scheduled on any of the available multiprocessors within a GPU, in any order, concurrently or sequentially, so that a compiled CUDA program can execute on any number of multiprocessors.</p>
<p><img alt="CUDA Automatic Scalability" src="https://docs.nvidia.com/cuda/cuda-c-programming-guide/graphics/automatic-scalability.png" width="800" /></p>
<div class="admonition warning">
<p class="admonition-title">The following exercise requires knowledge about <em>barrier synchronization</em> and <em>shared memory</em>.</p>
<p>Follow-up on <code>__syncthreads()</code> and <a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#shared-memory">shared memory</a>.</p>
</div>
<div class="admonition question">
<p class="admonition-title">04. Exercise: Fine-grained vs coarse-grained parallelism</p>
<ul>
<li>Give examples in the <code>MatMulKernel</code> kernel of <strong>coarse-grained</strong> and <strong>fine-grained data parallelism</strong> (as defined in CUDA abstraction model) as well as sequential execution.</li>
</ul>
<p><a href="../week01_exercises/#exercise_01_04">Go to exercise 01_04</a></p>
</div>
                
              
            </article>
          </div>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.sections", "content.tabs.link"], "translations": {"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "search": "../../../assets/javascripts/workers/search.01824240.min.js", "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.0d86bc28.min.js"></script>
      
    
  </body>
</html>