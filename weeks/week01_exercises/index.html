
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.2.3, mkdocs-material-8.0.0b1">
    
    
      
        <title>Week 01 - Exercises - CMS Tracker DPG - knowledge transfer workshop</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.450eaa28.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.9204c3b2.min.css">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>function __md_scope(e,t,_){return new URL(_||(t===localStorage?"../..":"../.."),location).pathname+"."+e}function __md_get(e,t=localStorage,_){return JSON.parse(t.getItem(__md_scope(e,t,_)))}function __md_set(e,t,_=localStorage,o){try{_.setItem(__md_scope(e,_,o),JSON.stringify(t))}catch(e){}}</script>
    
      

  


  

  


  <script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-ZZ8D6PMHP5"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){this.value&&gtag("event","search",{search_term:this.value})}),"undefined"!=typeof location$&&location$.subscribe(function(e){gtag("config","G-ZZ8D6PMHP5",{page_path:e.pathname})})})</script>
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-ZZ8D6PMHP5"></script>


    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="none" data-md-color-accent="none">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#week-01-exercises" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="CMS Tracker DPG - knowledge transfer workshop" class="md-header__button md-logo" aria-label="CMS Tracker DPG - knowledge transfer workshop" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            CMS Tracker DPG - knowledge transfer workshop
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Week 01 - Exercises
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="CMS Tracker DPG - knowledge transfer workshop" class="md-nav__button md-logo" aria-label="CMS Tracker DPG - knowledge transfer workshop" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    CMS Tracker DPG - knowledge transfer workshop
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_2">
          Connecting to GPU machines
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Connecting to GPU machines" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          Connecting to GPU machines
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../getting-started/" class="md-nav__link">
        Access to machines
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_3">
          Knowledge transfer material
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Knowledge transfer material" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Knowledge transfer material
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../week01/" class="md-nav__link">
        Week 01 - 2021.12.06-10.
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Week 01 - Exercises
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Week 01 - Exercises
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#exercise_01_01" class="md-nav__link">
    Exercise_01_01
  </a>
  
    <nav class="md-nav" aria-label="Exercise_01_01">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#question" class="md-nav__link">
    Question
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#solution" class="md-nav__link">
    Solution
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#exercise_01_02" class="md-nav__link">
    Exercise_01_02
  </a>
  
    <nav class="md-nav" aria-label="Exercise_01_02">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#question_1" class="md-nav__link">
    Question
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#solution_1" class="md-nav__link">
    Solution
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#exercise_01_03" class="md-nav__link">
    Exercise_01_03
  </a>
  
    <nav class="md-nav" aria-label="Exercise_01_03">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#exercise" class="md-nav__link">
    Exercise
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#exercise_01_04" class="md-nav__link">
    Exercise_01_04
  </a>
  
    <nav class="md-nav" aria-label="Exercise_01_04">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#exercise_1" class="md-nav__link">
    Exercise
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#solution_2" class="md-nav__link">
    Solution
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../week02/" class="md-nav__link">
        Week 02 - 2021.12.13-17.
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../week02_exercises/" class="md-nav__link">
        Week 02 - Exercises
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../further_reading/" class="md-nav__link">
        Further reading
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#exercise_01_01" class="md-nav__link">
    Exercise_01_01
  </a>
  
    <nav class="md-nav" aria-label="Exercise_01_01">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#question" class="md-nav__link">
    Question
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#solution" class="md-nav__link">
    Solution
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#exercise_01_02" class="md-nav__link">
    Exercise_01_02
  </a>
  
    <nav class="md-nav" aria-label="Exercise_01_02">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#question_1" class="md-nav__link">
    Question
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#solution_1" class="md-nav__link">
    Solution
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#exercise_01_03" class="md-nav__link">
    Exercise_01_03
  </a>
  
    <nav class="md-nav" aria-label="Exercise_01_03">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#exercise" class="md-nav__link">
    Exercise
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#exercise_01_04" class="md-nav__link">
    Exercise_01_04
  </a>
  
    <nav class="md-nav" aria-label="Exercise_01_04">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#exercise_1" class="md-nav__link">
    Exercise
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#solution_2" class="md-nav__link">
    Solution
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                
                
<h1 id="week-01-exercises">Week 01 - Exercises</h1>
<h2 id="exercise_01_01">Exercise_01_01</h2>
<h3 id="question">Question</h3>
<div class="admonition question">
<p class="admonition-title">01. Question: raw to digi conversion kernel</p>
<ul>
<li>Find the kernel that converts raw data to digis.</li>
<li>Where is it launched?</li>
<li>What is the execution configuration?</li>
<li>How do we access individual threads in the kernel?</li>
</ul>
<p>To search the source code use <a href="https://cmssdt.cern.ch/dxr/CMSSW/source/">CMSSW dxr - software cross-reference</a>.</p>
</div>
<h3 id="solution">Solution</h3>
<details class="example"><summary>01.a. Find the kernel that converts raw data to digis.</summary><div class="highlight"><pre><span></span><code>// Kernel to perform Raw to Digi conversion
__global__ void RawToDigi_kernel(const SiPixelROCsStatusAndMapping *cablingMap,
                                const unsigned char *modToUnp,
                                const uint32_t wordCounter,
                                const uint32_t *word,
                                const uint8_t *fedIds,
                                uint16_t *xx,
                                uint16_t *yy,
                                uint16_t *adc,
                                uint32_t *pdigi,
...
</code></pre></div>
</details>
<details class="example"><summary>01.b. Where is it launched?</summary><p>It is launched in the <code>makeClustersAsync</code> function:
<div class="highlight"><pre><span></span><code><span class="kt">void</span><span class="w"> </span><span class="n">SiPixelRawToClusterGPUKernel</span><span class="o">::</span><span class="n">makeClustersAsync</span><span class="p">(</span><span class="kt">bool</span><span class="w"> </span><span class="n">isRun2</span><span class="p">,</span><span class="w"></span>
<span class="w">                                                   </span><span class="k">const</span><span class="w"> </span><span class="n">SiPixelClusterThresholds</span><span class="w"> </span><span class="n">clusterThresholds</span><span class="p">,</span><span class="w"></span>
<span class="w">                                                   </span><span class="k">const</span><span class="w"> </span><span class="n">SiPixelROCsStatusAndMapping</span><span class="w"> </span><span class="o">*</span><span class="n">cablingMap</span><span class="p">,</span><span class="w"></span>
<span class="w">                                                   </span><span class="k">const</span><span class="w"> </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">modToUnp</span><span class="p">,</span><span class="w"></span>
<span class="w">                                                   </span><span class="k">const</span><span class="w"> </span><span class="n">SiPixelGainForHLTonGPU</span><span class="w"> </span><span class="o">*</span><span class="n">gains</span><span class="p">,</span><span class="w"></span>
<span class="w">                                                   </span><span class="k">const</span><span class="w"> </span><span class="n">WordFedAppender</span><span class="w"> </span><span class="o">&amp;</span><span class="n">wordFed</span><span class="p">,</span><span class="w"></span>
<span class="w">                                                   </span><span class="n">SiPixelFormatterErrors</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="n">errors</span><span class="p">,</span><span class="w"></span>
<span class="w">                                                   </span><span class="k">const</span><span class="w"> </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">wordCounter</span><span class="p">,</span><span class="w"></span>
<span class="p">...</span><span class="w">       </span>
<span class="c1">// Launch rawToDigi kernel</span>
<span class="w">  </span><span class="n">RawToDigi_kernel</span><span class="o">&lt;&lt;&lt;</span><span class="n">blocks</span><span class="p">,</span><span class="w"> </span><span class="n">threadsPerBlock</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">stream</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="w"></span>
<span class="w">      </span><span class="n">cablingMap</span><span class="p">,</span><span class="w"></span>
<span class="w">      </span><span class="n">modToUnp</span><span class="p">,</span><span class="w"></span>
<span class="w">      </span><span class="n">wordCounter</span><span class="p">,</span><span class="w"></span>
<span class="w">      </span><span class="n">word_d</span><span class="p">.</span><span class="n">get</span><span class="p">(),</span><span class="w"></span>
<span class="w">      </span><span class="n">fedId_d</span><span class="p">.</span><span class="n">get</span><span class="p">(),</span><span class="w"></span>
<span class="w">      </span><span class="n">digis_d</span><span class="p">.</span><span class="n">view</span><span class="p">().</span><span class="n">xx</span><span class="p">(),</span><span class="w"></span>
<span class="w">      </span><span class="n">digis_d</span><span class="p">.</span><span class="n">view</span><span class="p">().</span><span class="n">yy</span><span class="p">(),</span><span class="w"></span>
<span class="w">      </span><span class="n">digis_d</span><span class="p">.</span><span class="n">view</span><span class="p">().</span><span class="n">adc</span><span class="p">(),</span><span class="w"></span>
<span class="p">...</span><span class="w"></span>
</code></pre></div></p>
</details>
<details class="example"><summary>01.c. What is the execution configuration?</summary><p>For the <code>RawToDigi_kernel</code> he execution configuration is defined as
<div class="highlight"><pre><span></span><code><span class="o">&lt;&lt;&lt;</span><span class="n">blocks</span><span class="p">,</span><span class="w"> </span><span class="n">threadsPerBlock</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">stream</span><span class="o">&gt;&gt;&gt;</span><span class="w"></span>
</code></pre></div></p>
<p>Where 
<div class="highlight"><pre><span></span><code><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">threadsPerBlock</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">512</span><span class="p">;</span><span class="w"></span>
<span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">blocks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">wordCounter</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadsPerBlock</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">threadsPerBlock</span><span class="p">;</span><span class="w">  </span><span class="c1">// fill it all</span>
</code></pre></div></p>
<p>In this case </p>
<p><img alt="blocks" src="https://latex.codecogs.com/svg.image?blocks=\left&space;\lceil&space;\frac{wordCounter}{threadsPerBlock}&space;\right&space;\rceil" /></p>
</details>
<details class="example"><summary>01.d. How do we access individual threads in the kernel?</summary><div class="highlight"><pre><span></span><code><span class="kt">int32_t</span><span class="w"> </span><span class="n">first</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span><span class="w"></span>
</code></pre></div>
</details>
<h2 id="exercise_01_02">Exercise_01_02</h2>
<h3 id="question_1">Question</h3>
<div class="admonition question">
<p class="admonition-title">02. Question: host and device functions</p>
<ul>
<li>
<p>Give an example of <code>global</code>, <code>device</code> and <code>host-device</code> functions in <code>CMSSW</code>.</p>
</li>
<li>
<p>Can you find an example where <code>host</code> and <code>device</code> code diverge? How is this achieved?</p>
</li>
</ul>
</div>
<h3 id="solution_1">Solution</h3>
<details class="example"><summary>02.a. Give an example of <code>global</code>, <code>device</code> and <code>host-device</code> functions in <code>CMSSW</code>.</summary><p>For example see <code>__global__</code> kernel in <a href="weeks/week01_exercises/#solution_1">previous exercise</a>.</p>
<p><code>__device__</code> function in <a href="https://cmssdt.cern.ch/dxr/CMSSW/source/RecoLocalTracker/SiPixelClusterizer/plugins/SiPixelRawToClusterGPUKernel.cu#57">RecoLocalTracker/SiPixelClusterizer/plugins/SiPixelRawToClusterGPUKernel.cu</a>:
<div class="highlight"><pre><span></span><code><span class="kt">__device__</span><span class="w"> </span><span class="n">pixelgpudetails</span><span class="o">::</span><span class="n">DetIdGPU</span><span class="w"> </span><span class="n">getRawId</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">SiPixelROCsStatusAndMapping</span><span class="w"> </span><span class="o">*</span><span class="n">cablingMap</span><span class="p">,</span><span class="w"></span>
<span class="w">                                                </span><span class="kt">uint8_t</span><span class="w"> </span><span class="n">fed</span><span class="p">,</span><span class="w"></span>
<span class="w">                                                </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">link</span><span class="p">,</span><span class="w"></span>
<span class="w">                                                </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">roc</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fed</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">MAX_LINK</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">MAX_ROC</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">link</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">MAX_ROC</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">roc</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="n">pixelgpudetails</span><span class="o">::</span><span class="n">DetIdGPU</span><span class="w"> </span><span class="n">detId</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">        </span><span class="n">cablingMap</span><span class="o">-&gt;</span><span class="n">rawId</span><span class="p">[</span><span class="n">index</span><span class="p">],</span><span class="w"> </span><span class="n">cablingMap</span><span class="o">-&gt;</span><span class="n">rocInDet</span><span class="p">[</span><span class="n">index</span><span class="p">],</span><span class="w"> </span><span class="n">cablingMap</span><span class="o">-&gt;</span><span class="n">moduleId</span><span class="p">[</span><span class="n">index</span><span class="p">]};</span><span class="w"></span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">detId</span><span class="p">;</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</code></pre></div></p>
<p><code>__host__</code> <code>__device__</code>function in <a href="https://cmssdt.cern.ch/dxr/CMSSW/source/HeterogeneousCore/CUDAUtilities/interface/OneToManyAssoc.h#191">HeterogeneousCore/CUDAUtilities/interface/OneToManyAssoc.h</a>:
<div class="highlight"><pre><span></span><code><span class="kr">__host__</span><span class="w"> </span><span class="kt">__device__</span><span class="w"> </span><span class="kr">__forceinline__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">add</span><span class="p">(</span><span class="n">CountersOnly</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">&amp;</span><span class="n">co</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int32_t</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">totOnes</span><span class="p">();</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="cp">#ifdef __CUDA_ARCH__</span>
<span class="w">        </span><span class="n">atomicAdd</span><span class="p">(</span><span class="n">off</span><span class="p">.</span><span class="n">data</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">co</span><span class="p">.</span><span class="n">off</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span><span class="w"></span>
<span class="cp">#else</span>
<span class="w">        </span><span class="k">auto</span><span class="w"> </span><span class="o">&amp;</span><span class="n">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">atomic</span><span class="o">&lt;</span><span class="n">Counter</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="p">)(</span><span class="n">off</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span><span class="w"></span>
<span class="w">        </span><span class="n">a</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">co</span><span class="p">.</span><span class="n">off</span><span class="p">[</span><span class="n">i</span><span class="p">];</span><span class="w"></span>
<span class="cp">#endif</span>
<span class="w">    </span><span class="p">}</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</code></pre></div></p>
</details>
<details class="example"><summary>02.b. Can you find an example where host and device code diverge? How is this achieved?</summary><p>In the <a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#host">CUDA C Programming Guide</a> we can read that:</p>
<p>The <code>__device__</code> and <code>__host__</code> execution space specifiers can be used together however, in which case the function is compiled for both the host and the device.</p>
<p>The <code>__CUDA_ARCH__</code> macro introduced in Application Compatibility can be used to differentiate code paths between host and device:</p>
<div class="highlight"><pre><span></span><code><span class="kr">__host__</span><span class="w"> </span><span class="kt">__device__</span><span class="w"> </span><span class="n">func</span><span class="p">()</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="cp">#if __CUDA_ARCH__ &gt;= 800</span>
<span class="c1">// Device code path for compute capability 8.x</span>
<span class="cp">#elif __CUDA_ARCH__ &gt;= 700</span>
<span class="c1">// Device code path for compute capability 7.x</span>
<span class="cp">#elif __CUDA_ARCH__ &gt;= 600</span>
<span class="c1">// Device code path for compute capability 6.x</span>
<span class="cp">#elif __CUDA_ARCH__ &gt;= 500</span>
<span class="c1">// Device code path for compute capability 5.x</span>
<span class="cp">#elif __CUDA_ARCH__ &gt;= 300</span>
<span class="c1">// Device code path for compute capability 3.x</span>
<span class="cp">#elif !defined(__CUDA_ARCH__) </span>
<span class="c1">// Host code path</span>
<span class="cp">#endif</span>
<span class="p">}</span><span class="w"></span>
</code></pre></div>
<p>Based on this we can see how execution diverges in the previous <code>add</code> function:
<div class="highlight"><pre><span></span><code><span class="kr">__host__</span><span class="w"> </span><span class="kt">__device__</span><span class="w"> </span><span class="kr">__forceinline__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">add</span><span class="p">(</span><span class="n">CountersOnly</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="o">&amp;</span><span class="n">co</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int32_t</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">totOnes</span><span class="p">();</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="cp">#ifdef __CUDA_ARCH__</span>
<span class="w">        </span><span class="n">atomicAdd</span><span class="p">(</span><span class="n">off</span><span class="p">.</span><span class="n">data</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">co</span><span class="p">.</span><span class="n">off</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span><span class="w"></span>
<span class="cp">#else</span>
<span class="w">        </span><span class="k">auto</span><span class="w"> </span><span class="o">&amp;</span><span class="n">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">atomic</span><span class="o">&lt;</span><span class="n">Counter</span><span class="o">&gt;</span><span class="w"> </span><span class="o">&amp;</span><span class="p">)(</span><span class="n">off</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span><span class="w"></span>
<span class="w">        </span><span class="n">a</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">co</span><span class="p">.</span><span class="n">off</span><span class="p">[</span><span class="n">i</span><span class="p">];</span><span class="w"></span>
<span class="cp">#endif</span>
<span class="w">    </span><span class="p">}</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</code></pre></div></p>
</details>
<h2 id="exercise_01_03">Exercise_01_03</h2>
<h3 id="exercise">Exercise</h3>
<div class="admonition question">
<p class="admonition-title">03. Exercise: Write a kernel in which</p>
<ul>
<li>
<p>if we're running on the <code>device</code> each thread prints which <code>block</code> and <code>thread</code> it is associated with, for example <code>block 1 thread 3</code></p>
</li>
<li>
<p>if we're running on the <code>host</code> each thread just prints <code>host</code>.</p>
</li>
<li>
<p>Test your program!</p>
</li>
</ul>
</div>
<details class="tip"><summary>How can you "hide" your GPU?</summary><p>Try using <code>CUDA_VISIBLE_DEVICES</code> from the command line.</p>
</details>
<h2 id="exercise_01_04">Exercise_01_04</h2>
<h3 id="exercise_1">Exercise</h3>
<div class="admonition question">
<p class="admonition-title">04. Exercise: Fine-grained vs coarse-grained parallelism: Give examples in the <code>MatMulKernel</code> kernel of <strong>coarse-grained</strong> and <strong>fine-grained data parallelism</strong> (as defined in CUDA abstraction model) as well as sequential execution.</p>
<div class="tabbed-set tabbed-alternate" data-tabs="1:4"><input checked="checked" id="__tabbed_1_1" name="__tabbed_1" type="radio" /><input id="__tabbed_1_2" name="__tabbed_1" type="radio" /><input id="__tabbed_1_3" name="__tabbed_1" type="radio" /><input id="__tabbed_1_4" name="__tabbed_1" type="radio" /><div class="tabbed-labels"><label for="__tabbed_1_1">MatMulKernel</label><label for="__tabbed_1_2">Matrix definition</label><label for="__tabbed_1_3">GetElement and SetElement</label><label for="__tabbed_1_4">GetSubMatrix</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="c1">// Thread block size</span>
<span class="cp">#define BLOCK_SIZE 16</span>

<span class="w"> </span><span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">MatMulKernel</span><span class="p">(</span><span class="n">Matrix</span><span class="w"> </span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="n">Matrix</span><span class="w"> </span><span class="n">B</span><span class="p">,</span><span class="w"> </span><span class="n">Matrix</span><span class="w"> </span><span class="n">C</span><span class="p">)</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="c1">// Block row and column</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">blockRow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">blockCol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span><span class="w"></span>

<span class="w">    </span><span class="c1">// Each thread block computes one sub-matrix Csub of C</span>
<span class="w">    </span><span class="n">Matrix</span><span class="w"> </span><span class="n">Csub</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">GetSubMatrix</span><span class="p">(</span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="n">blockRow</span><span class="p">,</span><span class="w"> </span><span class="n">blockCol</span><span class="p">);</span><span class="w"></span>

<span class="w">    </span><span class="c1">// Each thread computes one element of Csub</span>
<span class="w">    </span><span class="c1">// by accumulating results into Cvalue</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">Cvalue</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"></span>

<span class="w">    </span><span class="c1">// Thread row and column within Csub</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span><span class="w"></span>

<span class="w">    </span><span class="c1">// Loop over all the sub-matrices of A and B that are</span>
<span class="w">    </span><span class="c1">// required to compute Csub</span>
<span class="w">    </span><span class="c1">// Multiply each pair of sub-matrices together</span>
<span class="w">    </span><span class="c1">// and accumulate the results</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="p">(</span><span class="n">A</span><span class="p">.</span><span class="n">width</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">BLOCK_SIZE</span><span class="p">);</span><span class="w"> </span><span class="o">++</span><span class="n">m</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>

<span class="w">        </span><span class="c1">// Get sub-matrix Asub of A</span>
<span class="w">        </span><span class="n">Matrix</span><span class="w"> </span><span class="n">Asub</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">GetSubMatrix</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="n">blockRow</span><span class="p">,</span><span class="w"> </span><span class="n">m</span><span class="p">);</span><span class="w"></span>

<span class="w">        </span><span class="c1">// Get sub-matrix Bsub of B</span>
<span class="w">        </span><span class="n">Matrix</span><span class="w"> </span><span class="n">Bsub</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">GetSubMatrix</span><span class="p">(</span><span class="n">B</span><span class="p">,</span><span class="w"> </span><span class="n">m</span><span class="p">,</span><span class="w"> </span><span class="n">blockCol</span><span class="p">);</span><span class="w"></span>

<span class="w">        </span><span class="c1">// Shared memory used to store Asub and Bsub respectively</span>
<span class="w">        </span><span class="kt">__shared__</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">As</span><span class="p">[</span><span class="n">BLOCK_SIZE</span><span class="p">][</span><span class="n">BLOCK_SIZE</span><span class="p">];</span><span class="w"></span>
<span class="w">        </span><span class="kt">__shared__</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">Bs</span><span class="p">[</span><span class="n">BLOCK_SIZE</span><span class="p">][</span><span class="n">BLOCK_SIZE</span><span class="p">];</span><span class="w"></span>

<span class="w">        </span><span class="c1">// Load Asub and Bsub from device memory to shared memory</span>
<span class="w">        </span><span class="c1">// Each thread loads one element of each sub-matrix</span>
<span class="w">        </span><span class="n">As</span><span class="p">[</span><span class="n">row</span><span class="p">][</span><span class="n">col</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">GetElement</span><span class="p">(</span><span class="n">Asub</span><span class="p">,</span><span class="w"> </span><span class="n">row</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="p">);</span><span class="w"></span>
<span class="w">        </span><span class="n">Bs</span><span class="p">[</span><span class="n">row</span><span class="p">][</span><span class="n">col</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">GetElement</span><span class="p">(</span><span class="n">Bsub</span><span class="p">,</span><span class="w"> </span><span class="n">row</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="p">);</span><span class="w"></span>

<span class="w">        </span><span class="c1">// Synchronize to make sure the sub-matrices are loaded</span>
<span class="w">        </span><span class="c1">// before starting the computation</span>
<span class="w">        </span><span class="nf">__syncthreads</span><span class="p">();</span><span class="w"></span>
<span class="w">        </span><span class="c1">// Multiply Asub and Bsub together</span>
<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">e</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">e</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">BLOCK_SIZE</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">e</span><span class="p">)</span><span class="w"></span>
<span class="w">            </span><span class="n">Cvalue</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">As</span><span class="p">[</span><span class="n">row</span><span class="p">][</span><span class="n">e</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">Bs</span><span class="p">[</span><span class="n">e</span><span class="p">][</span><span class="n">col</span><span class="p">];</span><span class="w"></span>

<span class="w">        </span><span class="c1">// Synchronize to make sure that the preceding</span>
<span class="w">        </span><span class="c1">// computation is done before loading two new</span>
<span class="w">        </span><span class="c1">// sub-matrices of A and B in the next iteration</span>
<span class="w">        </span><span class="nf">__syncthreads</span><span class="p">();</span><span class="w"></span>
<span class="w">    </span><span class="p">}</span><span class="w"></span>

<span class="w">    </span><span class="c1">// Write Csub to device memory</span>
<span class="w">    </span><span class="c1">// Each thread writes one element</span>
<span class="w">    </span><span class="n">SetElement</span><span class="p">(</span><span class="n">Csub</span><span class="p">,</span><span class="w"> </span><span class="n">row</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="p">,</span><span class="w"> </span><span class="n">Cvalue</span><span class="p">);</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</code></pre></div>
</div>
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="c1">// Matrices are stored in row-major order:</span>
<span class="c1">// M(row, col) = *(M.elements + row * M.stride + col)</span>
<span class="k">typedef</span><span class="w"> </span><span class="k">struct</span> <span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">width</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">height</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">stride</span><span class="p">;</span><span class="w"> </span>
<span class="w">    </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">elements</span><span class="p">;</span><span class="w"></span>
<span class="p">}</span><span class="w"> </span><span class="n">Matrix</span><span class="p">;</span><span class="w"></span>
</code></pre></div>
</div>
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="c1">// Get a matrix element</span>
<span class="kt">__device__</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">GetElement</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">Matrix</span><span class="w"> </span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">row</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">col</span><span class="p">)</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">A</span><span class="p">.</span><span class="n">elements</span><span class="p">[</span><span class="n">row</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">A</span><span class="p">.</span><span class="n">stride</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">col</span><span class="p">];</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>

<span class="c1">// Set a matrix element</span>
<span class="kt">__device__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">SetElement</span><span class="p">(</span><span class="n">Matrix</span><span class="w"> </span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">row</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">col</span><span class="p">,</span><span class="w"></span>
<span class="w">                        </span><span class="kt">float</span><span class="w"> </span><span class="n">value</span><span class="p">)</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="n">A</span><span class="p">.</span><span class="n">elements</span><span class="p">[</span><span class="n">row</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">A</span><span class="p">.</span><span class="n">stride</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">col</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">value</span><span class="p">;</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</code></pre></div>
</div>
<div class="tabbed-block">
<div class="highlight"><pre><span></span><code><span class="c1">// Get the BLOCK_SIZExBLOCK_SIZE sub-matrix Asub of A that is</span>
<span class="c1">// located col sub-matrices to the right and row sub-matrices down</span>
<span class="c1">// from the upper-left corner of A</span>
<span class="kt">__device__</span><span class="w"> </span><span class="n">Matrix</span><span class="w"> </span><span class="n">GetSubMatrix</span><span class="p">(</span><span class="n">Matrix</span><span class="w"> </span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">row</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">col</span><span class="p">)</span><span class="w"> </span>
<span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="n">Matrix</span><span class="w"> </span><span class="n">Asub</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="n">Asub</span><span class="p">.</span><span class="n">width</span><span class="w">    </span><span class="o">=</span><span class="w"> </span><span class="n">BLOCK_SIZE</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="n">Asub</span><span class="p">.</span><span class="n">height</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="n">BLOCK_SIZE</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="n">Asub</span><span class="p">.</span><span class="n">stride</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="n">A</span><span class="p">.</span><span class="n">stride</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="n">Asub</span><span class="p">.</span><span class="n">elements</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">&amp;</span><span class="n">A</span><span class="p">.</span><span class="n">elements</span><span class="p">[</span><span class="n">A</span><span class="p">.</span><span class="n">stride</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">BLOCK_SIZE</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">row</span><span class="w"></span>
<span class="w">                                        </span><span class="o">+</span><span class="w"> </span><span class="n">BLOCK_SIZE</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">col</span><span class="p">];</span><span class="w"></span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">Asub</span><span class="p">;</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</code></pre></div>
</div>
</div>
</div>
</div>
<p><img alt="Matrix Multiplication with Shared Memory" src="https://docs.nvidia.com/cuda/cuda-c-programming-guide/graphics/matrix-multiplication-with-shared-memory.png" width="900" /></p>
<h3 id="solution_2">Solution</h3>
<details class="example"><summary>04.a. Give examples in the <code>MatMulKernel</code> kernel of <strong>coarse-grained data parallelism</strong>.</summary><p>Coarse-grained data parallel problems in the CUDA programming model are problems that can be solved independently in parallel by blocks of threads.</p>
<p>For example in the <code>MatMulKernel</code>:</p>
<div class="highlight"><pre><span></span><code><span class="w"> </span><span class="c1">// Block row and column</span>
<span class="kt">int</span><span class="w"> </span><span class="n">blockRow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span><span class="w"></span>
<span class="kt">int</span><span class="w"> </span><span class="n">blockCol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span><span class="w"></span>

<span class="c1">// Each thread block computes one sub-matrix Csub of C</span>
<span class="n">Matrix</span><span class="w"> </span><span class="n">Csub</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">GetSubMatrix</span><span class="p">(</span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="n">blockRow</span><span class="p">,</span><span class="w"> </span><span class="n">blockCol</span><span class="p">);</span><span class="w"></span>
</code></pre></div>
<p>The computation of <code>Csub</code> is independent of the computation of other submatrices of <code>C</code>. The work is divided between <code>blocks</code>, no synchronization is performed between computing different <code>submatrices of C</code>.</p>
</details>
<details class="example"><summary>04.b. Give examples in the <code>MatMulKernel</code> kernel of <strong>fine-grained data parallelism</strong>.</summary><p>Fine-grained data parallel problems in the CUDA programming model are finer pieces that can be solved cooperatively in parallel by all threads within the block.</p>
<p>For example in the <code>MatMulKernel</code>:</p>
<div class="highlight"><pre><span></span><code><span class="c1">// Get sub-matrix Asub of A</span>
<span class="n">Matrix</span><span class="w"> </span><span class="n">Asub</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">GetSubMatrix</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="n">blockRow</span><span class="p">,</span><span class="w"> </span><span class="n">m</span><span class="p">);</span><span class="w"></span>

<span class="c1">// Get sub-matrix Bsub of B</span>
<span class="n">Matrix</span><span class="w"> </span><span class="n">Bsub</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">GetSubMatrix</span><span class="p">(</span><span class="n">B</span><span class="p">,</span><span class="w"> </span><span class="n">m</span><span class="p">,</span><span class="w"> </span><span class="n">blockCol</span><span class="p">);</span><span class="w"></span>

<span class="c1">// Shared memory used to store Asub and Bsub respectively</span>
<span class="kt">__shared__</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">As</span><span class="p">[</span><span class="n">BLOCK_SIZE</span><span class="p">][</span><span class="n">BLOCK_SIZE</span><span class="p">];</span><span class="w"></span>
<span class="kt">__shared__</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">Bs</span><span class="p">[</span><span class="n">BLOCK_SIZE</span><span class="p">][</span><span class="n">BLOCK_SIZE</span><span class="p">];</span><span class="w"></span>

<span class="c1">// Load Asub and Bsub from device memory to shared memory</span>
<span class="c1">// Each thread loads one element of each sub-matrix</span>
<span class="n">As</span><span class="p">[</span><span class="n">row</span><span class="p">][</span><span class="n">col</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">GetElement</span><span class="p">(</span><span class="n">Asub</span><span class="p">,</span><span class="w"> </span><span class="n">row</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="p">);</span><span class="w"></span>
<span class="n">Bs</span><span class="p">[</span><span class="n">row</span><span class="p">][</span><span class="n">col</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">GetElement</span><span class="p">(</span><span class="n">Bsub</span><span class="p">,</span><span class="w"> </span><span class="n">row</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="p">);</span><span class="w"></span>

<span class="c1">// Synchronize to make sure the sub-matrices are loaded</span>
<span class="c1">// before starting the computation</span>
<span class="nf">__syncthreads</span><span class="p">();</span><span class="w"></span>
</code></pre></div>
<p>Loading data into shared memory blocks of <code>matrix A and B</code> is executed parellel by all threads within the block.</p>
</details>
<details class="example"><summary>04.c. Give examples in the <code>MatMulKernel</code> kernel of <strong>sequential execution</strong>.</summary><div class="highlight"><pre><span></span><code><span class="c1">// Multiply Asub and Bsub together</span>
<span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">e</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">e</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">BLOCK_SIZE</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">e</span><span class="p">)</span><span class="w"></span>
<span class="w">    </span><span class="n">Cvalue</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">As</span><span class="p">[</span><span class="n">row</span><span class="p">][</span><span class="n">e</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">Bs</span><span class="p">[</span><span class="n">e</span><span class="p">][</span><span class="n">col</span><span class="p">];</span><span class="w"></span>
</code></pre></div>
<p>The computation of <code>Cvalue</code> for each thread is sequential, we execute <code>BLOCK_SIZE</code> additions and multiplications.</p>
<p>On the other hand the computation of <code>Cvalue</code> is also a good example of <em>fine-grained</em> data parallelism, since there is one value computed by each thread in the block parallel.</p>
<p>To identify <em>fine-grained</em> parallelism one just needs to look for block-level synchronization:</p>
<div class="highlight"><pre><span></span><code><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">e</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">e</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">BLOCK_SIZE</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">e</span><span class="p">)</span><span class="w"></span>
<span class="w">    </span><span class="n">Cvalue</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">As</span><span class="p">[</span><span class="n">row</span><span class="p">][</span><span class="n">e</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">Bs</span><span class="p">[</span><span class="n">e</span><span class="p">][</span><span class="n">col</span><span class="p">];</span><span class="w"></span>

<span class="c1">// Synchronize to make sure that the preceding</span>
<span class="c1">// computation is done before loading two new</span>
<span class="c1">// sub-matrices of A and B in the next iteration</span>
<span class="nf">__syncthreads</span><span class="p">();</span><span class="w"></span>
</code></pre></div>
</details>
                
              
            </article>
          </div>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    <nav class="md-footer__inner md-grid" aria-label="Footer">
      
        
        <a href="../week01/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Week 01 - 2021.12.06-10." rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              Week 01 - 2021.12.06-10.
            </div>
          </div>
        </a>
      
      
        
        <a href="../week02/" class="md-footer__link md-footer__link--next" aria-label="Next: Week 02 - 2021.12.13-17." rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              Week 02 - 2021.12.13-17.
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.sections", "content.tabs.link"], "translations": {"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "search": "../../assets/javascripts/workers/search.01824240.min.js", "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.0d86bc28.min.js"></script>
      
    
  </body>
</html>